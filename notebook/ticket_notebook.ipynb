{
 "cells": [
  {
   "cell_type": "code",
   "id": "f811cc1c-0a84-464d-8b46-2b45082c52bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.311337Z",
     "start_time": "2025-02-05T10:30:03.307507Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Imposta PROJECT_ROOT come la cartella principale (astromark-ai), un livello sopra \"notebook\"\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "print(\"[INFO] Project root aggiunto a sys.path:\", PROJECT_ROOT)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Project root aggiunto a sys.path: H:\\Informatica\\astromark-ai\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "e3f75e39-9eb8-4a3a-a44c-2d0b1f6e2e2a",
   "metadata": {},
   "source": [
    "# Notebook Astromark AI\n",
    "\n",
    "Questo notebook carica i dati dei ticket, li unisce e li preprocessa (utilizzando spaCy per tokenizzazione, lemmatizzazione e NER), costruisce la pipeline di ML, esegue la grid search, salva/carica il modello e infine fornisce un esempio di utilizzo del ticket service."
   ]
  },
  {
   "cell_type": "code",
   "id": "e5ad5d70-73c4-4ae7-9381-53ef1a9a9bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.343071Z",
     "start_time": "2025-02-05T10:30:03.338074Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from enum import Enum\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "# Imposta i percorsi relativi al project root\n",
    "BASE_DIR = PROJECT_ROOT\n",
    "DATA_RAW_DIR = os.path.join(BASE_DIR, 'data', 'raw')\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "TRAINED_DIR = os.path.join(BASE_DIR, 'data', 'trained')\n",
    "\n",
    "TICKET_O3_PATH = os.path.join(DATA_RAW_DIR, 'ticket-o3.csv')\n",
    "TICKET_GEMINI_PATH = os.path.join(DATA_RAW_DIR, 'ticket-gemini-claude.csv')\n",
    "PROCESSED_DATA_PATH = os.path.join(PROCESSED_DIR, 'X_processed.csv')\n",
    "\n",
    "os.makedirs(DATA_RAW_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(TRAINED_DIR, exist_ok=True)\n",
    "\n",
    "print('[INFO] Percorso per ticket-o3:', TICKET_O3_PATH)\n",
    "print('[INFO] Percorso per ticket-gemini:', TICKET_GEMINI_PATH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Percorso per ticket-o3: H:\\Informatica\\astromark-ai\\data\\raw\\ticket-o3.csv\n",
      "[INFO] Percorso per ticket-gemini: H:\\Informatica\\astromark-ai\\data\\raw\\ticket-gemini-claude.csv\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "6149d1dc-fbd9-4248-9c38-9c8839ab1a07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.387530Z",
     "start_time": "2025-02-05T10:30:03.365352Z"
    }
   },
   "source": [
    "# Caricamento e unione dei dati\n",
    "print('[INFO] Caricamento di ticket-o3...')\n",
    "dataframe_o3 = pd.read_csv(TICKET_O3_PATH, usecols=['titolo', 'messaggio', 'categoria'])\n",
    "print(f'[INFO] ticket-o3.csv caricato con shape: {dataframe_o3.shape}')\n",
    "\n",
    "print('[INFO] Caricamento di ticket-gemini-claude...')\n",
    "dataframe_gc = pd.read_csv(TICKET_GEMINI_PATH, usecols=['titolo', 'messaggio', 'categoria'])\n",
    "print(f'[INFO] ticket-gemini-claude.csv caricato con shape: {dataframe_gc.shape}')\n",
    "\n",
    "def merge_dataframes(frame1, frame2):\n",
    "    print('[INFO] Unione dei dataframe...')\n",
    "    frame = pd.concat([frame1, frame2])\n",
    "    frame['titolo_messaggio'] = frame['titolo'] + ' ' + frame['messaggio']\n",
    "    return frame[['titolo_messaggio', 'categoria']]\n",
    "\n",
    "merged_df = merge_dataframes(dataframe_o3, dataframe_gc)\n",
    "X = merged_df['titolo_messaggio']\n",
    "y = merged_df['categoria']\n",
    "print(f'[INFO] Dataset unito finale: {merged_df.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Caricamento di ticket-o3...\n",
      "[INFO] ticket-o3.csv caricato con shape: (4027, 3)\n",
      "[INFO] Caricamento di ticket-gemini-claude...\n",
      "[INFO] ticket-gemini-claude.csv caricato con shape: (866, 3)\n",
      "[INFO] Unione dei dataframe...\n",
      "[INFO] Dataset unito finale: (4893, 2)\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "a8a43f1d-9f64-4b75-9a32-dc264b4a607b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.706111Z",
     "start_time": "2025-02-05T10:30:03.399306Z"
    }
   },
   "source": [
    "# Preprocessing minimo del testo con spaCy\n",
    "print('[INFO] Caricamento del modello spaCy (it_core_news_sm)...')\n",
    "nlp = spacy.load('it_core_news_sm')\n",
    "\n",
    "# Definiamo i saluti da rimuovere\n",
    "GREETINGS_PATTERNS = [\n",
    "    r'\\bciao\\b', r'\\bbuongiorno\\b', r'\\bsalve\\b',\n",
    "    r'\\bbuonasera\\b', r'\\bbuon pomeriggio\\b', r'\\barrivederci\\b',\n",
    "    r'\\bbuonanotte\\b', r'\\ba presto\\b', r'\\baddio\\b', r'\\bsaluti\\b'\n",
    "]\n",
    "\n",
    "def remove_greetings(text):\n",
    "    pattern = re.compile('|'.join(GREETINGS_PATTERNS), flags=re.IGNORECASE)\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "def minimal_preprocess(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # rimozione URL\n",
    "    text = remove_greetings(text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # rimozione punteggiatura\n",
    "    text = re.sub(r'\\d+', '', text)  # rimozione numeri\n",
    "    text = re.sub(r'\\s+', ' ', text)  # normalizzazione spazi\n",
    "    return text.strip()\n",
    "\n",
    "def process_text(text):\n",
    "    cleaned_text = minimal_preprocess(text)\n",
    "    doc = nlp(cleaned_text)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct or token.is_space:\n",
    "            continue\n",
    "        lemma = token.lemma_\n",
    "        if lemma:\n",
    "            lemma = lemma.strip()\n",
    "            if lemma:\n",
    "                tokens.append(lemma)\n",
    "    for ent in doc.ents:\n",
    "        tokens.append(f\"NER_{ent.label_}\")\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def parallel_process_texts(series, n_jobs=-1):\n",
    "    print('[INFO] Preprocessing in parallelo con backend threading...')\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        processed = Parallel()(delayed(process_text)(text) for text in series)\n",
    "    return pd.Series(processed, index=series.index)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Caricamento del modello spaCy (it_core_news_sm)...\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "4b4e05fa-5b4f-4a5c-8b93-3ea32029ac0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.731785Z",
     "start_time": "2025-02-05T10:30:03.718222Z"
    }
   },
   "source": [
    "# Carica o processa i dati preprocessati\n",
    "if os.path.exists(PROCESSED_DATA_PATH):\n",
    "    print(f\"[INFO] Caricamento dei dati preprocessati da '{PROCESSED_DATA_PATH}'...\")\n",
    "    df = pd.read_csv(PROCESSED_DATA_PATH)\n",
    "    X_processed = df[\"processed_text\"]\n",
    "else:\n",
    "    print('[INFO] Dati preprocessati non trovati, inizio preprocessing in parallelo...')\n",
    "    X_processed = parallel_process_texts(X, n_jobs=-1)\n",
    "    print('[INFO] Salvataggio dei dati preprocessati in:', PROCESSED_DATA_PATH)\n",
    "    X_processed_df = pd.DataFrame(X_processed, columns=[\"processed_text\"])\n",
    "    X_processed_df.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "    print('[INFO] Preprocessing completato e memorizzato.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Caricamento dei dati preprocessati da 'H:\\Informatica\\astromark-ai\\data\\processed\\X_processed.csv'...\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "f7a74a96-8db9-4f6a-8f1a-f35aace7ce3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.746379Z",
     "start_time": "2025-02-05T10:30:03.743489Z"
    }
   },
   "source": "from service.pipeline import ClassifierType",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "0311fc80-0f71-4e6d-b82a-bba6e88b3ec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.762037Z",
     "start_time": "2025-02-05T10:30:03.757405Z"
    }
   },
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Funzioni per costruire la pipeline e la Grid Search\n",
    "def build_pipeline(classifier_type):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        use_idf=True,\n",
    "        ngram_range=(1, 1),\n",
    "        max_features=2000,\n",
    "        norm='l2',\n",
    "        smooth_idf=True,\n",
    "        sublinear_tf=True\n",
    "    )\n",
    "\n",
    "    if classifier_type == ClassifierType.NAIVE_BAYES:\n",
    "        classifier = MultinomialNB()\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', tfidf),\n",
    "            ('clf', classifier)\n",
    "        ])\n",
    "        param_grid = {\n",
    "            'tfidf__min_df': [1, 3],\n",
    "            'tfidf__max_df': [0.85, 0.90],\n",
    "            'clf__alpha': [1.0, 1.5, 2.0]\n",
    "        }\n",
    "    elif classifier_type == ClassifierType.SVM:\n",
    "        svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "        classifier = SVC(probability=True, kernel='linear', random_state=42)\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', tfidf),\n",
    "            ('svd', svd),\n",
    "            ('clf', classifier)\n",
    "        ])\n",
    "        param_grid = {\n",
    "            'tfidf__min_df': [1, 3],\n",
    "            'tfidf__max_df': [0.85, 0.90],\n",
    "            'svd__n_components': [30, 50],\n",
    "            'clf__C': [0.1, 0.5, 1.0]\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported classifier type.\")\n",
    "    return pipeline, param_grid\n",
    "\n",
    "def perform_grid_search(X, y, classifier_type):\n",
    "    print(f\"[INFO] Costruisco la pipeline per {classifier_type.value}...\")\n",
    "    pipeline, param_grid = build_pipeline(classifier_type)\n",
    "    print(f\"[INFO] Avvio Grid Search per {classifier_type.value} con parametri: {param_grid}\")\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=skf, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X, y)\n",
    "    print(f\"[INFO] Grid Search per {classifier_type.value} completata.\")\n",
    "    print(f\"[INFO] Parametri migliori: {grid.best_params_}\")\n",
    "    return grid.best_estimator_\n"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "fd2892b2-8b9e-4f98-85d8-407e15b4b4a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.794551Z",
     "start_time": "2025-02-05T10:30:03.781146Z"
    }
   },
   "source": [
    "# Funzioni per salvare/caricare il modello\n",
    "MODEL_PATHS = {\n",
    "    \"naive_bayes\": os.path.join(TRAINED_DIR, \"trained_model_nb.pkl\"),\n",
    "    \"svm\": os.path.join(TRAINED_DIR, \"trained_model_svm.pkl\")\n",
    "}\n",
    "\n",
    "def save_model(model, classifier_type):\n",
    "    path = MODEL_PATHS[classifier_type.value]\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"[INFO] Modello salvato in {path}.\")\n",
    "\n",
    "def load_model(classifier_type):\n",
    "    path = MODEL_PATHS[classifier_type.value]\n",
    "    if os.path.exists(path):\n",
    "        print(f\"[INFO] Caricamento del modello da {path}...\")\n",
    "        return joblib.load(path)\n",
    "    return None\n",
    "\n",
    "def get_model(classifier_type):\n",
    "    \"\"\"Se esiste un modello preaddestrato, lo carica; altrimenti esegue la grid search e lo salva.\"\"\"\n",
    "    model = load_model(classifier_type)\n",
    "    if model is None:\n",
    "        print(f\"[INFO] Nessun modello salvato per {classifier_type.value}. Avvio training...\")\n",
    "        model = perform_grid_search(X_processed, y, classifier_type)\n",
    "        save_model(model, classifier_type)\n",
    "    else:\n",
    "        print(f\"[INFO] Uso il modello salvato per {classifier_type.value}.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "selected_classifier = ClassifierType.SVM\n",
    "print(f\"[INFO] Classificatore selezionato: {selected_classifier.value}\")\n",
    "\n",
    "print(\"[INFO] Recupero del modello finale (lo carico se già esistente)...\")\n",
    "final_model = get_model(selected_classifier)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Classificatore selezionato: svm\n",
      "[INFO] Recupero del modello finale (lo carico se già esistente)...\n",
      "[INFO] Caricamento del modello da H:\\Informatica\\astromark-ai\\data\\trained\\trained_model_svm.pkl...\n",
      "[INFO] Uso il modello salvato per svm.\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "a65a49d5-3e3c-4c07-bdf3-22cdeb0d7e1b",
   "metadata": {},
   "source": [
    "## Fine della Pipeline\n",
    "\n",
    "I dati sono stati caricati, preprocessati e il modello (ottenuto tramite Grid Search) è stato caricato o addestrato e salvato nella cartella `../data/trained`."
   ]
  },
  {
   "cell_type": "code",
   "id": "ddf7b90e-5e0f-4d31-a8f9-0b2a43a9295e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T10:30:03.817590Z",
     "start_time": "2025-02-05T10:30:03.798557Z"
    }
   },
   "source": [
    "# Esempio: Funzione per il Ticket Service\n",
    "def ticket_service(title, message):\n",
    "    full_text = f\"{title} {message}\".strip()\n",
    "    if not full_text:\n",
    "        return [\"Nessun input fornito\"]\n",
    "    # Importa la funzione predict_category dal modulo report_predict\n",
    "    from service.report_predict import predict_category\n",
    "    predictions = predict_category(full_text, selected_classifier)\n",
    "    print(\"Predizioni:\", predictions)\n",
    "    return predictions\n",
    "\n",
    "# Esempio di utilizzo\n",
    "example_title = \"Problema con la stampante\"\n",
    "example_message = \"La stampante non funziona correttamente.\"\n",
    "ticket_service(example_title, example_message)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting category for a new message...\n",
      "[INFO] Loading saved model from H:\\Informatica\\astromark-ai\\service\\..\\data\\trained\\trained_model_svm.pkl...\n",
      "[INFO] Using saved model for svm.\n",
      "Predizioni: [('Tecnico', np.float64(0.8865087359950377)), ('Accesso', np.float64(0.038013852204738206)), ('Didattica', np.float64(0.03588015307661468))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Tecnico', np.float64(0.8865087359950377)),\n",
       " ('Accesso', np.float64(0.038013852204738206)),\n",
       " ('Didattica', np.float64(0.03588015307661468))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
